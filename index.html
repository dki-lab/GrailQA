<!DOCTYPE html><!--Author: Pranav Rajpurkar 2016--><html><head><!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-183531080-2"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-183531080-2');
</script><meta charset="utf-8"><title>Strongly Generalizable Question Answering Dataset</title><meta name="description" content="Strongly Generalizable Question Answering Dataset (GrailQA) is a new large-scale, high-quality dataset for question answering on knowledge bases (KBQA) on Freebase with 64,331 questions annotated with both answers and corresponding logical forms in different syntax (i.e., SPARQL, S-expression, etc.). It can be used to test three levels of generalization in KBQA: i.i.d., compositional, and zero-shot."><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no"><meta property="og:image" content="/logo.png"><link rel="image_src" type="image/png" href="/GrailQA/logo.png"><link rel="shortcut icon" href="/GrailQA/favicon.ico" type="image/x-icon"><link rel="icon" href="/GrailQA/favicon.ico" type="image/x-icon"><link rel="stylesheet" href="/GrailQA/bower_components/bootstrap/dist/css/bootstrap.min.css"><link rel="stylesheet" href="/GrailQA/stylesheets/layout.css"><link rel="stylesheet" href="/GrailQA/stylesheets/index.css"><script async defer src="https://buttons.github.io/buttons.js"></script><script src="/GrailQA/javascripts/analytics.js"></script></head><body><div class="navbar navbar-default navbar-fixed-top" id="topNavbar" role="navigation"><div class="container clearfix" id="navContainer"><div class="rightNav"><div class="collapseDiv"><button class="navbar-toggle collapsed" type="button" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar"><span class="glyphicon glyphicon-menu-hamburger"></span></button></div><div class="collapse navbar-collapse" id="navbar"><ul class="nav navbar-nav navbar-right"><li><a href="/GrailQA/">Home</a></li><li><a href="/GrailQA/explore/grailqa/">Explore GrailQA</a></li></ul></div></div><div class="leftNav"><div class="brandDiv"><a class="navbar-brand" href="/GrailQA/">GrailQA</a></div></div></div></div><div class="cover" id="topCover"><div class="container"><div class="row"><div class="col-md-12"><h1 id="appTitle"> <b>GrailQA</b></h1><h2 id="appSubtitle">The Strongly Generalizable Question Answering Dataset</h2></div></div></div></div><div class="cover" id="contentCover"><div class="container"><div class="row"><div class="col-md-5"><div class="infoCard"><div class="infoBody"><div class="infoHeadline"><h2>What is GrailQA?</h2></div><p> <span>Strongly <b>G</b>ene<b>ra</b>l<b>i</b>zab<b>l</b>e <b>Q</b>uestion <b>A</b>nswering <Dataset>(GrailQA) </Dataset></span>is a new large-scale, high-quality dataset for question answering on knowledge bases (KBQA) on Freebase with 64,331 questions annotated with both answers and corresponding logical forms in different syntax (i.e., SPARQL, S-expression, etc.). It can be used to test three levels of generalization in KBQA: i.i.d., compositional, and zero-shot.</p><a class="btn actionBtn" href="/GrailQA/explore/grailqa/">Explore GrailQA</a><a class="btn actionBtn" href="https://arxiv.org/abs/2011.07743">GrailQA paper (Gu et al. '20)</a><hr><div class="infoHeadline"><h2>Why GrailQA?</h2></div><p> GrailQA is by far the largest crowdsourced KBQA dataset with questions of high diversity (i.e., questions in GrailQA can have up to 4 relations and optionally have a function from counting, superlatives and comparatives). It also has the highest coverage over Freebase; it widely covers 3,720 relations and 86 domains from Freebase. Last but not least, our meticulous data split allows GrailQA to test not only i.i.d. generalization, but also compositional generalization and zero-shot generalization, which are critical for practical KBQA systems.</p><div class="infoHeadline"><h2>News</h2></div><ul class="list-unstyled" style="background-color:#f5f5f5"><li><span class="date label label-default" style="background-color:#d8ab1f"><i>12/14/2020</i></span> We update all the numbers in our paper. The previous numbers were not accurate because we made some update to our datasets after that.</li><li><span class="date label label-default" style="background-color:#d8ab1f"><i>11/30/2020</i></span> We fix some minor error in the sparql_queries provided in our dataset.</li></ul><div class="infoHeadline"><h2>Getting Started</h2></div><p>We've built a few resources to help you get started with the dataset.</p><p> Download a copy of the dataset (distributed under the  <a href="http://creativecommons.org/licenses/by-sa/4.0/legalcode">CC BY-SA 4.0</a> license):<ul class="list-unstyled"><li><a class="btn actionBtn inverseBtn" href="https://dl.orangedox.com/WyaCpL/" download>GrailQA Dataset (120 MB)</a></li></ul></p><hr><p> To work with our dataset, we recommend you setting up a Virtuoso server for Freebase (feel free to choose your own way to index Freebase). Please find both a clean version of Freebase dump and instructions on setting up the server via:<ul class="list-unstyled"><li><a class="btn actionBtn inverseBtn" href="https://github.com/dki-lab/Freebase-Setup" download>Freebase Setup</a></li></ul></p><hr><p>To evaluate your models, we have also made available the evaluation script we will use for official evaluation, along with a sample prediction file that the script will take as input. Evaluating semantic-level exact match also depends on several preprocessed ontology files of Freebase. You can find all of them <a href="https://worksheets.codalab.org/worksheets/0xf5592764ac8a475abc1eb747e246066c">here. </a>To run the evaluation, use <code>python evaluate.py &lt;path_to_dev&gt; &lt;path_to_predictions&gt; --fb_roles &lt;path_to_fb_roles&gt;  --fb_types &lt;path_to_fb_types&gt; --reverse_properties &lt;path_to_reverse_properties&gt;</code>.<ul class="list-unstyled"><li><a class="btn actionBtn inverseBtn" href="https://worksheets.codalab.org/bundles/0x2d13989c17e44690ab62cc4edc0b900d/" download>Evaluation Script</a></li><li><a class="btn actionBtn inverseBtn" href="https://worksheets.codalab.org/bundles/0x23cbaa41769a43bd987cd23b7baaceb5/" download>Sample Prediction File (on Dev Set)</a></li></ul></p><p>Once you have a built a model that works to your expectations on the dev set, you submit it to get official scores on the dev and a hidden test set. To preserve the integrity of test results, we do not release the labels of test set to the public. Here's a tutorial walking you through official evaluation of your model:</p><a class="btn actionBtn inverseBtn" href="https://worksheets.codalab.org/worksheets/0xd51b9aa5cf374ee598f1d6422cd976f3">Submission Tutorial</a><div class="infoHeadline"><h2>Have Questions?</h2></div><p> Send an email to <a href="mailto:gu.826@osu.edu">gu.826@osu.edu</a>, or create an issue in <a href="https://github.com/dki-lab/GrailQA">github.</a></p><div class="infoHeadline"><h2>Acknowledgement</h2></div><p>We thank <a href="https://rajpurkar.github.io/">Pranav Rajpurkar</a> and <a href="https://robinjia.github.io/">Robin Jia </a>for giving us the permission to build this website based on <a href="https://rajpurkar.github.io/SQuAD-explorer/">SQuAD.  </a></p></div><div class="infoSubheadline"><a href="https://twitter.com/share" class="twitter-share-button" data-url="https://dki-lab.github.io/GrailQA" data-text="The Strongly Generalizable Question Answering Dataset - 60,000+ questions for KBQA" data-via="osu dki lab" data-size="large" data-hashtags="GrailQA">Tweet</a> <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script></div></div></div><div class="col-md-7"><div class="infoCard"><div class="infoBody"><div class="infoHeadline"><h2>Leaderboard: Overall</h2></div><p>Here are the overall Exact Match (EM) and F1 scores evaluated on GrailQA test set. To get the EM score on GrailQA, please submit your results with logical forms in S-expression. Note that, submissions are ranked only based on F1, so feel free to choose your own meaning representation as EM won't affect your ranking.</p><table class="table performanceTable"><tr><th>Rank</th><th>Model</th><th>EM</th><th>F1</th></tr><tr><td> <p>1</p><span class="date label label-default">Dec 10, 2020</span></td><td style="word-break:break-word;">BERT+Ranking (single model)<p class="institution">The Ohio State University</p></td><td><b>31.192</b></td><td><b>36.668</b></td></tr><tr><td> <p>2</p><span class="date label label-default">Dec 10, 2020</span></td><td style="word-break:break-word;">GloVe+Ranking (single model)<p class="institution">The Ohio State University</p></td><td>24.299</td><td>28.490</td></tr><tr><td> <p>3</p><span class="date label label-default">Dec 10, 2020</span></td><td style="word-break:break-word;">BERT+Transduction (single model)<p class="institution">The Ohio State University</p></td><td>24.760</td><td>27.920</td></tr><tr><td> <p>4</p><span class="date label label-default">Dec 10, 2020</span></td><td style="word-break:break-word;">GloVe+Transduction (single model)<p class="institution">The Ohio State University</p></td><td>12.962</td><td>13.695</td></tr></table></div></div><div class="infoCard"><div class="infoBody"><div class="infoHeadline"><h2>Leaderboard: Compositional Generalization</h2></div><p>Here are the Exact Match (EM) and F1 scores evaluated on the subset of GrailQA test set that tests compositional generalization.</p><table class="table performanceTable"><tr><th>Rank</th><th>Model</th><th>EM</th><th>F1</th></tr><tr><td> <p>1</p><span class="date label label-default">Dec 10, 2020</span></td><td style="word-break:break-word;">BERT+Ranking (single model)<p class="institution">The Ohio State University</p></td><td><b>27.487</b></td><td><b>33.589</b></td></tr><tr><td> <p>2</p><span class="date label label-default">Dec 10, 2020</span></td><td style="word-break:break-word;">GloVe+Ranking (single model)<p class="institution">The Ohio State University</p></td><td>24.548</td><td>30.576</td></tr><tr><td> <p>3</p><span class="date label label-default">Dec 10, 2020</span></td><td style="word-break:break-word;">BERT+Transduction (single model)<p class="institution">The Ohio State University</p></td><td>24.160</td><td>28.375</td></tr><tr><td> <p>4</p><span class="date label label-default">Dec 10, 2020</span></td><td style="word-break:break-word;">GloVe+Transduction (single model)<p class="institution">The Ohio State University</p></td><td>12.468</td><td>14.144</td></tr></table></div></div><div class="infoCard"><div class="infoBody"><div class="infoHeadline"><h2>Leaderboard: Zero-shot Generalization</h2></div><p>Here are the Exact Match (EM) and F1 scores evaluated on the subset of GrailQA test set that tests zero-shot generalization.</p><table class="table performanceTable"><tr><th>Rank</th><th>Model</th><th>EM</th><th>F1</th></tr><tr><td> <p>1</p><span class="date label label-default">Dec 10, 2020</span></td><td style="word-break:break-word;">BERT+Ranking (single model)<p class="institution">The Ohio State University</p></td><td><b>30.486</b></td><td><b>35.774</b></td></tr><tr><td> <p>2</p><span class="date label label-default">Dec 10, 2020</span></td><td style="word-break:break-word;">BERT+Transduction (single model)<p class="institution">The Ohio State University</p></td><td>19.507</td><td>22.741</td></tr><tr><td> <p>3</p><span class="date label label-default">Dec 10, 2020</span></td><td style="word-break:break-word;">GloVe+Ranking (single model)<p class="institution">The Ohio State University</p></td><td>17.879</td><td>21.509</td></tr><tr><td> <p>4</p><span class="date label label-default">Dec 10, 2020</span></td><td style="word-break:break-word;">GloVe+Transduction (single model)<p class="institution">The Ohio State University</p></td><td>2.031</td><td>2.214</td></tr></table></div></div></div></div></div></div><script src="/GrailQA/bower_components/jquery/dist/jquery.min.js"></script><script src="/GrailQA/bower_components/bootstrap/dist/js/bootstrap.min.js"></script></body></html>
